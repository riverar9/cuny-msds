{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974299da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from ipywidgets import interact, widgets\n",
    "import warnings\n",
    "import os\n",
    "import requests\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "def get_us_state_to_abbrev():\n",
    "    return {\n",
    "        \"Alabama\": \"AL\",\n",
    "        \"Alaska\": \"AK\",\n",
    "        \"Arizona\": \"AZ\",\n",
    "        \"Arkansas\": \"AR\",\n",
    "        \"California\": \"CA\",\n",
    "        \"Colorado\": \"CO\",\n",
    "        \"Connecticut\": \"CT\",\n",
    "        \"Delaware\": \"DE\",\n",
    "        \"Florida\": \"FL\",\n",
    "        \"Georgia\": \"GA\",\n",
    "        \"Hawaii\": \"HI\",\n",
    "        \"Idaho\": \"ID\",\n",
    "        \"Illinois\": \"IL\",\n",
    "        \"Indiana\": \"IN\",\n",
    "        \"Iowa\": \"IA\",\n",
    "        \"Kansas\": \"KS\",\n",
    "        \"Kentucky\": \"KY\",\n",
    "        \"Louisiana\": \"LA\",\n",
    "        \"Maine\": \"ME\",\n",
    "        \"Maryland\": \"MD\",\n",
    "        \"Massachusetts\": \"MA\",\n",
    "        \"Michigan\": \"MI\",\n",
    "        \"Minnesota\": \"MN\",\n",
    "        \"Mississippi\": \"MS\",\n",
    "        \"Missouri\": \"MO\",\n",
    "        \"Montana\": \"MT\",\n",
    "        \"Nebraska\": \"NE\",\n",
    "        \"Nevada\": \"NV\",\n",
    "        \"New Hampshire\": \"NH\",\n",
    "        \"New Jersey\": \"NJ\",\n",
    "        \"New Mexico\": \"NM\",\n",
    "        \"New York\": \"NY\",\n",
    "        \"North Carolina\": \"NC\",\n",
    "        \"North Dakota\": \"ND\",\n",
    "        \"Ohio\": \"OH\",\n",
    "        \"Oklahoma\": \"OK\",\n",
    "        \"Oregon\": \"OR\",\n",
    "        \"Pennsylvania\": \"PA\",\n",
    "        \"Rhode Island\": \"RI\",\n",
    "        \"South Carolina\": \"SC\",\n",
    "        \"South Dakota\": \"SD\",\n",
    "        \"Tennessee\": \"TN\",\n",
    "        \"Texas\": \"TX\",\n",
    "        \"Utah\": \"UT\",\n",
    "        \"Vermont\": \"VT\",\n",
    "        \"Virginia\": \"VA\",\n",
    "        \"Washington\": \"WA\",\n",
    "        \"West Virginia\": \"WV\",\n",
    "        \"Wisconsin\": \"WI\",\n",
    "        \"Wyoming\": \"WY\",\n",
    "        \"District of Columbia\": \"DC\",\n",
    "        \"American Samoa\": \"AS\",\n",
    "        \"Guam\": \"GU\",\n",
    "        \"Northern Mariana Islands\": \"MP\",\n",
    "        \"Puerto Rico\": \"PR\",\n",
    "        \"United States Minor Outlying Islands\": \"UM\",\n",
    "        \"U.S. Virgin Islands\": \"VI\", # Or \"Virgin Islands\"\n",
    "        \"Virgin Islands\": \"VI\" # Common variation\n",
    "    }\n",
    "\n",
    "def get_consumption_data():\n",
    "    file_loc = 'data/state_consumption.csv'\n",
    "    directory = os.path.dirname(file_loc)\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    if not os.path.exists(file_loc):\n",
    "        try:\n",
    "            response = requests.get('https://raw.githubusercontent.com/riverar9/cuny-msds/refs/heads/main/data608-knowledge-and-visual-analytics/stories/story-7/data/state_consumption.csv')\n",
    "            response.raise_for_status()\n",
    "            with open(file_loc, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "        except Exception as e:\n",
    "            raise Exception(e)\n",
    "    \n",
    "    df = pd.read_csv('data/state_consumption.csv')\n",
    "\n",
    "    # Drop the 'Rank' column as it's not needed for the transformation\n",
    "    df = df.drop(columns=['Rank'])\n",
    "\n",
    "    # Initialize an empty list to store individual DataFrames for each fuel source\n",
    "    dfs_to_concat = []\n",
    "\n",
    "    # Define the fuel sources based on the column naming pattern\n",
    "    fuel_sources_map = {\n",
    "        'Coal': ('State_Coal', 'Trillion_Btu_Coal'),\n",
    "        'Natural Gas': ('State_Natural_Gas', 'Trillion_Btu_Natural_Gas'),\n",
    "        'Petroleum': ('State_Petroleum', 'Trillion_Btu_Petroleum'),\n",
    "        'Nuclear': ('State_Nuclear', 'Trillion_Btu_Nuclear'),\n",
    "        'Total Renewable Energy': ('State_Total_Renewable_Energy', 'Trillion_Btu_Total_Renewable_Energy')\n",
    "    }\n",
    "\n",
    "    for fuel_name, (state_col, btu_col) in fuel_sources_map.items():\n",
    "        # Select the relevant state and BTU columns\n",
    "        temp_df = df[[state_col, btu_col]].copy()\n",
    "        # Rename columns to a standard format for concatenation\n",
    "        temp_df.columns = ['State', 'Trillions BTU Consumed']\n",
    "        # Add the 'Fuel Source' column\n",
    "        temp_df['Fuel Source'] = fuel_name\n",
    "        # Append to the list\n",
    "        dfs_to_concat.append(temp_df)\n",
    "\n",
    "    # Concatenate all the temporary DataFrames\n",
    "    result_df = pd.concat(dfs_to_concat, ignore_index=True)\n",
    "\n",
    "    # Data Cleaning:\n",
    "    # 1. Remove commas from 'Trillions BTU Consumed'\n",
    "    # 2. Convert 'Trillions BTU Consumed' to numeric\n",
    "    result_df['Trillions BTU Consumed'] = result_df['Trillions BTU Consumed'].astype(str).str.replace(',', '', regex=False)\n",
    "    result_df['Trillions BTU Consumed'] = pd.to_numeric(result_df['Trillions BTU Consumed'])\n",
    "\n",
    "    # Reorder columns to the desired format\n",
    "    result_df = result_df[['State', 'Fuel Source', 'Trillions BTU Consumed']]\n",
    "\n",
    "    total_df = result_df[['State','Trillions BTU Consumed']].groupby('State').sum().reset_index()\n",
    "    total_df['Fuel Source'] = \"Total\"\n",
    "\n",
    "    result_df = pd.concat([result_df,total_df])\n",
    "\n",
    "    return result_df\n",
    "\n",
    "def get_generation_data():\n",
    "    file_loc = 'data/state_generation.csv'\n",
    "    directory = os.path.dirname(file_loc)\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    if not os.path.exists(file_loc):\n",
    "        try:\n",
    "            response = requests.get('https://raw.githubusercontent.com/riverar9/cuny-msds/refs/heads/main/data608-knowledge-and-visual-analytics/stories/story-7/data/state_generation.csv')\n",
    "            response.raise_for_status()\n",
    "            with open(file_loc, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "        except Exception as e:\n",
    "            raise Exception(e)\n",
    "\n",
    "    df =  pd.read_csv(file_loc)\n",
    "\n",
    "    df = df.drop(\n",
    "        columns = 'Total'\n",
    "    )\n",
    "\n",
    "    df.columns = ['State', 'Coal', 'Natural Gas', 'Petroleum', 'Nuclear', 'Total Renewable Energy', 'Total Renewable Energy', 'Total Renewable Energy']\n",
    "\n",
    "    df = df.melt(id_vars= ['State'], value_name='Trillions BTU Generated', var_name='Fuel Source')\n",
    "\n",
    "    df = df.groupby(['State','Fuel Source']).sum().reset_index()\n",
    "\n",
    "    total_df = df[['State','Trillions BTU Generated']].groupby('State').sum().reset_index()\n",
    "    total_df['Fuel Source'] = 'Total'\n",
    "\n",
    "    df = pd.concat([df, total_df])\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_dataset():\n",
    "    con_df = get_consumption_data()\n",
    "\n",
    "    gen_df = get_generation_data()\n",
    "\n",
    "    energy_df = con_df.merge(\n",
    "        gen_df,\n",
    "        on = ['State','Fuel Source'],\n",
    "        how = 'outer'\n",
    "    )\n",
    "\n",
    "    energy_df['State'] = energy_df['State'].replace(get_us_state_to_abbrev())\n",
    "\n",
    "    energy_df['net_export'] = energy_df['Trillions BTU Generated'] - energy_df['Trillions BTU Consumed']\n",
    "    energy_df.head()\n",
    "    \n",
    "    state_totals = energy_df.groupby('State').sum(numeric_only=True).reset_index()\n",
    "    state_totals = state_totals.drop(columns = 'net_export')\n",
    "    state_totals.columns = ['State','tot_consumed','tot_generated']\n",
    "\n",
    "    energy_df = energy_df.merge(\n",
    "        state_totals,\n",
    "        on = 'State'\n",
    "    )\n",
    "\n",
    "    energy_df['state_pct_consumed'] = energy_df['Trillions BTU Consumed'] / energy_df['tot_consumed']\n",
    "    energy_df['state_pct_generated'] = energy_df['Trillions BTU Generated'] / energy_df['tot_generated']\n",
    "\n",
    "    energy_df.columns = ['State','Fuel Source','Energy Consumption (TBTU)', 'Energy Generation (TBTU)', 'Net Exports (TBTU)','tot_consumed','tot_generated','Consumption by Source Percentage','Generation by Source Percentage']\n",
    "\n",
    "    return energy_df\n",
    "\n",
    "def plot_interactive_energy_map(selected_fuel_source, selected_kpi):\n",
    "    \"\"\"\n",
    "    Filters the energy_df by fuel source and plots the selected KPI on a US choropleth map.\n",
    "    \"\"\"\n",
    "    energy_df = get_dataset()\n",
    "\n",
    "    # Filter DataFrame based on selected fuel source\n",
    "    filtered_df = energy_df[energy_df['Fuel Source'] == selected_fuel_source].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        print(f\"No data available for Fuel Source: {selected_fuel_source} and KPI: {selected_kpi}\")\n",
    "        return\n",
    "\n",
    "    # Determine color scale and midpoint\n",
    "    if selected_kpi == 'Net Exports (TBTU)':\n",
    "        color_scale = px.colors.diverging.RdYlGn  # Red-Yellow-Green for diverging\n",
    "        color_midpoint = 0                        # Center at zero\n",
    "    elif selected_kpi in ['Energy Generation (TBTU)', 'Generation by Source Percentage']:\n",
    "        # For generation, use shades of green\n",
    "        color_scale = px.colors.sequential.Greens # A common sequential green scale\n",
    "        # Alternatives: px.colors.sequential.YlGn, px.colors.sequential.Emrld\n",
    "        color_midpoint = None                     # Sequential scales don't typically need a specific midpoint\n",
    "    elif selected_kpi in ['Energy Consumption (TBTU)', 'Consumption by Source Percentage']:\n",
    "        # For consumption, use shades of orange/red (not too harsh)\n",
    "        color_scale = px.colors.sequential.YlOrRd # Yellow-Orange-Red is a good, softer option\n",
    "        # Alternatives: px.colors.sequential.Oranges, px.colors.sequential.OrRd, px.colors.sequential.Reds (might be too strong)\n",
    "        color_midpoint = None\n",
    "    else:\n",
    "        # Default for any other KPIs\n",
    "        color_scale = 'Viridis' # A common, perceptually uniform sequential scale\n",
    "        color_midpoint = None\n",
    "\n",
    "    # Create the choropleth map\n",
    "    fig = px.choropleth(\n",
    "        filtered_df,\n",
    "        locations=filtered_df['State'],  \n",
    "        locationmode='USA-states',      \n",
    "        color=selected_kpi,             \n",
    "        scope='usa',                     \n",
    "        color_continuous_scale=color_scale,\n",
    "        color_continuous_midpoint=color_midpoint,\n",
    "        hover_name='State',              \n",
    "        hover_data={                     \n",
    "            'Fuel Source': True,         \n",
    "            selected_kpi: ':.2f',        \n",
    "            'Energy Consumption (TBTU)': ':.2f',\n",
    "            'Energy Generation (TBTU)': ':.2f',\n",
    "            'Net Exports (TBTU)': ':.2f'\n",
    "        },\n",
    "        title=f'US Energy Data: {selected_kpi} for {selected_fuel_source}'\n",
    "    )\n",
    "\n",
    "    # Further layout customization\n",
    "    fig.update_layout(\n",
    "        margin={\"r\":0, \"t\":40, \"l\":0, \"b\":0}, # Adjust margins\n",
    "        geo=dict(\n",
    "            lakecolor='rgb(255, 255, 255)',   # Set lake color to white\n",
    "            # To explicitly show only continental US, you might need to adjust center and projection\n",
    "            # For example, to try and center on continental US (might need tweaking):\n",
    "            # projection_scale=0.9, # Adjust scale if needed\n",
    "            # center=dict(lon=-98, lat=39)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "# %%\n",
    "def main():\n",
    "    energy_df = get_dataset()\n",
    "    \n",
    "    kpi_columns = ['Energy Consumption (TBTU)', 'Energy Generation (TBTU)', 'Net Exports (TBTU)','Consumption by Source Percentage','Generation by Source Percentage']\n",
    "\n",
    "    fuel_sources = sorted(energy_df['Fuel Source'].unique())\n",
    "\n",
    "    fuel_source_dropdown = widgets.Dropdown(\n",
    "        options=fuel_sources,\n",
    "        value=\"Total\", # Default to the first fuel source\n",
    "        description='Fuel Source:',\n",
    "        style={'description_width': 'initial'} # Adjust width to show full description\n",
    "    )\n",
    "\n",
    "    kpi_dropdown = widgets.Dropdown(\n",
    "        options=kpi_columns,\n",
    "        value='Energy Generation (TBTU)', # Default to 'net_export' as per specific color request\n",
    "        description='Select KPI:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "    interact(plot_interactive_energy_map, selected_fuel_source=fuel_source_dropdown, selected_kpi=kpi_dropdown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5894039e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'state_consumption.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 238\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m     energy_df = \u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    240\u001b[39m     kpi_columns = [\u001b[33m'\u001b[39m\u001b[33mEnergy Consumption (TBTU)\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mEnergy Generation (TBTU)\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mNet Exports (TBTU)\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mConsumption by Source Percentage\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mGeneration by Source Percentage\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    242\u001b[39m     fuel_sources = \u001b[38;5;28msorted\u001b[39m(energy_df[\u001b[33m'\u001b[39m\u001b[33mFuel Source\u001b[39m\u001b[33m'\u001b[39m].unique())\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 139\u001b[39m, in \u001b[36mget_dataset\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_dataset\u001b[39m():\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     con_df = \u001b[43mget_consumption_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m     gen_df = get_generation_data()\n\u001b[32m    143\u001b[39m     energy_df = con_df.merge(\n\u001b[32m    144\u001b[39m         gen_df,\n\u001b[32m    145\u001b[39m         on = [\u001b[33m'\u001b[39m\u001b[33mState\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mFuel Source\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    146\u001b[39m         how = \u001b[33m'\u001b[39m\u001b[33mouter\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    147\u001b[39m     )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 72\u001b[39m, in \u001b[36mget_consumption_data\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_consumption_data\u001b[39m():\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstate_consumption.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m     \u001b[38;5;66;03m# Drop the 'Rank' column as it's not needed for the transformation\u001b[39;00m\n\u001b[32m     75\u001b[39m     df = df.drop(columns=[\u001b[33m'\u001b[39m\u001b[33mRank\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/cuny-msds/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/cuny-msds/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/cuny-msds/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/cuny-msds/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/cuny-msds/.venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'state_consumption.csv'"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8e2d26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
