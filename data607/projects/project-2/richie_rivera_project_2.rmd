---
title: "Data 607 - Project 2"
author: "Richie R."
output:
  pdf_document: default
  html_document: default
---

# Overview
In this project, we will explore three of the datasets and analysis question presented within Discussion 5.

The three analysis that will be performed in this will be:

1. G. Schneider's "Consumer Price Index 2024"
2. Z. Liang's "U.S Vehicle Model Sales"
3. R. Rivera's "Car Crash information over time (1994-Present)"

```{r importing packages}
library(tidyverse)
library(dplyr)

# For HTML web scraping
library(rvest)

# R has a useful package to read excel files
library(readxl)
```

## 1. G. Schneider's "Consumer Price Index 2024"

```{r reading in the data}
data_url_1 <- "https://github.com/GuillermoCharlesSchneider/DATA-607/raw/main/CPI%202024.xlsx"

# the read_excel function can only work on local files,
# so it'll need to be downloaded
download.file(data_url_1, "guis_cpi.xlsx", mode = "wb")

cpi_df <- read_excel("guis_cpi.xlsx", sheet = "Sheet0")

head(cpi_df)
```

This data is pretty messy. So to clean it up, let's start with the unecessary rows. We'll do this by removing any `NA` entries in the fourth column `...4`:

```{r cleanup rows}
cpi_df <- cpi_df |>
  drop_na(...4)

head(cpi_df)
```

There's good descriptive information in the first two rows of data. In order to ensure that we don't lose any information, we will need to combine the first two rows and turn that into the header then remove the first two rows from the dataset.
I discovered that I can simply use the paste function as  *paste(row_1, row_2)* in order to combine each columns values in these rows. Using that, I can change the column name and remove these two rows.

```{r turning row 1 into column names}
colnames(cpi_df) <- paste(cpi_df[1, ], cpi_df[2, ])

# Removing a row will need to be done twice.
# This will be performed with a for loop
rows_removed <- 0
while (rows_removed < 2) {
  cpi_df <- cpi_df[-1, ]
  rows_removed <- rows_removed + 1
}

head(cpi_df)
```

I really don't like these column names, so let's clean these up by removing the `\r`, `\n`, and `\t` values.

This can be done using gsub and regex looking for any non-alpha-numeric items of length 1 or more and replacing them with an `_` character.

```{r removing special characters from column names}
colnames(cpi_df) <- gsub(
  "[^a-zA-Z0-9]{1,}",
  "_",
  colnames(cpi_df)
)

colnames(cpi_df)
```

Now that we have our columns, let's go ahead and convert numeric columns into numeric datatypes. This seems to be all the columns in the dataframe.
In order to pass all the columns in the dataframe, we'll use the `setdiff(columns, columnn_to_exclude)` function to select all columns except the one we're interested in.

Then, we can convert the remaining columns using the `mutate_at()` function:

```{r converting columns to numeric}
numeric_cols <- setdiff(colnames(cpi_df), "Expenditure_category_NA")

cpi_df <- cpi_df |>
  mutate_at(vars(numeric_cols), as.numeric)

str(cpi_df)
```

In most instances, I find that the percent change isn't available but this dataset seems to already have these fields calculated. So I will proceed by simply sorting the data by the `Unadjusted indexes Dec 2023` and then resort by `Unadjusted indexes Jan 2024` in descending order to see which categories had the greatest increase.

```{r Investigate the YoY changes}
top_yoy_changes <- cpi_df |>
  arrange(desc(Unadjusted_percent_change_Jan_2023_Jan_2024)) |>
  select(
    Indent_Level_NA,
    Expenditure_category_NA,
    Unadjusted_percent_change_Jan_2023_Jan_2024
  ) |>
  top_n(10)

top_yoy_changes

ggplot(
  data = top_yoy_changes,
  aes(
    x = Unadjusted_percent_change_Jan_2023_Jan_2024 / 100,
    y = reorder(
      Expenditure_category_NA,
      Unadjusted_percent_change_Jan_2023_Jan_2024
    )
  )
) +
  geom_bar(
    stat = "identity",
    fill = "forestgreen"
  ) +
  labs(
    x = "Percent Change",
    y = "Expenditure Category",
    title = "Year over Year CPI Increase "
  ) +
  scale_x_continuous(labels = scales::percent_format())

```

The code above has returned the top 10 expense categories and their year over year percent change. From here we can see that motor vehicle insurance has gone up **a whopping 20.6%**! [The New York Times](https://www.nytimes.com/2024/02/29/business/economy/auto-insurance-inflation.html) seems to have an article where they go over some reasons for this but this was something I wasn't aware of at all, thanks to living in NYC. It was unintentional, but it seems that each of the datasets I chosen will have an element investigating cars.

Following Motor Vehicle insurance, I see that transportation services and tobacco take the second and third place spots for increases in cost at 9.5% and 7.4%, respectively.

Now I'm curious, did anything get cheaper? We can investigate this by flipping our `arrange()`. This can be done by removing the `desc()`. Additionally, we will need to change our `top_n(10)` to be a `-10`:

```{r Investigate the things that got cheaper YoY}
bot_yoy_changes <- cpi_df |>
  arrange(Unadjusted_percent_change_Jan_2023_Jan_2024) |>
  select(
    Indent_Level_NA,
    Expenditure_category_NA,
    Unadjusted_percent_change_Jan_2023_Jan_2024
  ) |>
  top_n(-10)

bot_yoy_changes

ggplot(
  data = bot_yoy_changes,
  aes(
    x = Unadjusted_percent_change_Jan_2023_Jan_2024 / 100,
    y = reorder(
      Expenditure_category_NA,
      Unadjusted_percent_change_Jan_2023_Jan_2024
    )
  )
) +
  geom_bar(
    stat = "identity",
    fill = "firebrick1"
  ) +
  labs(
    x = "Percent Change",
    y = "Expenditure Category",
    title = "Year over Year CPI Increase "
  ) +
  scale_x_continuous(labels = scales::percent_format())

```

My first impression here is my sympathy for the environment. Each of the items on this list are large contributors of climate change with 8 of the 10 top items directly burning hydrocarbons. Admittedly, two of these entries are "parent" categories to others on this list, it's not a good sign that it's getting even cheaper to pollute the atmosphere.

Moving on, let's investigate the change From December 2023 to January 2024. We will do this by applying the same approach as year over year:

```{r Investigate the MoM changes}
top_mom_changes <- cpi_df |>
  arrange(desc(Unadjusted_percent_change_Dec_2023_Jan_2024)) |>
  select(
    Indent_Level_NA,
    Expenditure_category_NA,
    Unadjusted_percent_change_Dec_2023_Jan_2024
  ) |>
  top_n(10)

top_mom_changes

ggplot(
  data = top_mom_changes,
  aes(
    x = Unadjusted_percent_change_Dec_2023_Jan_2024 / 100,
    y = reorder(
      Expenditure_category_NA,
      Unadjusted_percent_change_Dec_2023_Jan_2024
    )
  )
) +
  geom_bar(
    stat = "identity",
    fill = "forestgreen"
  ) +
  labs(
    x = "Percent Change",
    y = "Expenditure Category",
    title = "Month over Month CPI Increase "
  ) +
  scale_x_continuous(labels = scales::percent_format())

```

From here, we see that month over month, Electricity and Energy services have increased the most at 2.5% and 2.5%, respectively. These are pretty significant monthly changes although I theorize that these two categories may be correlated with the U.S experiencing winter. As the months get colder, energy demand increases across the board. This is backed up by the [U.S. Energy Information Administration](https://www.eia.gov/todayinenergy/detail.php?id=29112#:~:text=EIA's%20Short%2DTerm%20Energy%20Outlook%20(STEO)%20projects%20that,warmer%20than%20expected%2C%20as%20they%20have%20been).

Now, as I'm curious, I'd also like to see what has gotten cheaper month to month:

```{r what has gotten cheaper MoM}
bot_mom_changes <- cpi_df |>
  arrange(Unadjusted_percent_change_Dec_2023_Jan_2024) |>
  select(
    Indent_Level_NA,
    Expenditure_category_NA,
    Unadjusted_percent_change_Dec_2023_Jan_2024
  ) |>
  top_n(-10)

bot_mom_changes

ggplot(
  data = bot_mom_changes,
  aes(
    x = Unadjusted_percent_change_Dec_2023_Jan_2024 / 100,
    y = reorder(
      Expenditure_category_NA,
      Unadjusted_percent_change_Dec_2023_Jan_2024
    )
  )
) +
  geom_bar(
    aes(
      fill = ifelse(
        Unadjusted_percent_change_Dec_2023_Jan_2024 < 0,
        "firebrick1",
        "forestgreen"
      )
    ),
    stat = "identity"
  ) +
  labs(
    x = "Percent Change",
    y = "Expenditure Category",
    title = "Month over Month CPI Increase "
  ) +
  scale_x_continuous(labels = scales::percent_format()) + 
  scale_fill_identity()
```

I'm not sure exactly what I was expecting, but significantly lowered used car prices was not one of them although many of the energy products which were cheaper year over year were also cheaper month to month. After the 6th entry on the list (Medical care commodities), there is a pretty small change in the month-to-month cost, which I was anticipating.

## 2. Z. Liang's "U.S Vehicle Model Sales"

In this dataset, Zixian suggest that we investigate the change in sales between motor vehicles. Using data from [goodbadcar.net](https://www.goodcarbadcar.net/2023-us-vehicle-sales-figures-by-model/), we can compare relative year over year growth of cars as this dataset represents total sales volume per vehicle brand and model.

Doing research for this, I found a useful package called `rvest` which allows me to easily scrape data from an online table by simply specifying the table tag.

In order to read this data, we'll use the HTML of the website along with the `read_html` and `html_table` functions to take the raw html from the website and parse the contents to obtain the data from the second table. This second table contains the year over year growth of sales per model of car.

```{r get the data}
data_url_2 <- "https://www.goodcarbadcar.net/2023-us-vehicle-sales-figures-by-model/"
webpage <- read_html(data_url_2)

table_id <- "table_2"
selected_table <- html_table(html_nodes(webpage, sprintf("#%s", table_id)))

car_sales_data <- selected_table[[1]]

colnames(car_sales_data) <- make.names(colnames(car_sales_data))

car_sales_data
```

We must convert the sales volume columns into numeric columns:

```{r data type conversions}
car_numeric_cols <- setdiff(colnames(car_sales_data), "modelName")

car_sales_data <- car_sales_data |>
  mutate(across(car_numeric_cols, ~as.numeric(gsub(",", "", .))))

str(car_sales_data)
```

This dataset seems relatively complete. With this, we are able to determine much about cars such as the total year over year change and percent change. With that, we will look at the top 10 and bottom 10 models by total year over change and compare that to the percent change.

```{r most sold car}
car_sales_data <- car_sales_data |>
  mutate(yoy_change = Q4.2023 - Q4.2022) |>
  mutate(yoy_pct_change = round(yoy_change / Q4.2022, 2))

average_growth <- sum(car_sales_data$yoy_change) / sum(car_sales_data$Q4.2022)

average_growth

top_car_sales <- car_sales_data |>
  top_n(10, yoy_change)

bot_car_sales <- car_sales_data |>
  top_n(-10, yoy_change)

visualization_data <- rbind(
  top_car_sales,
  bot_car_sales
)

visualization_data |>
  select(
    modelName,
    yoy_change,
    yoy_pct_change
  ) |>
  arrange(
    desc(yoy_change)
  )

car_sales_yoy <- ggplot(
  visualization_data,
  aes(y = reorder(modelName, yoy_change))
) +
  geom_bar(
    aes(
      x = yoy_change,
      fill = ifelse(
        yoy_change < 0,
        "firebrick1",
        "forestgreen"
      )
    ),
    stat = "identity",
    position = "dodge"
  ) +
  geom_text(
    aes(
      x = yoy_pct_change,
      label = paste(100 * yoy_pct_change, "%")
    ),
    position = position_dodge(width = 0.75),
    hjust = 0,
    size = 3
  ) +
  theme_minimal() +
  labs(
    x = "Year over Year Change in Sales",
    y = "Vehicle Model",
    title = "Vehicle Sales Year-over-Year Change by Model"
  ) +
  scale_fill_identity()

car_sales_yoy
```

The graph above shows the vehicle models with the greatest increase in total car sales and the greatest decrease in sales. From here, we can see that despite the Honda CR-V having the greatest year over year increase, it's only had a 67% growth. The second entry in the list, the Chevrolet Trax, has a comparable increase in sales year over year but a staggering 836% increase! Even more impressive, the Volkswagen Jetta has a 15100% Increase in sales! Additionally, we can see that there was an infinite increase in the Toyota Grant Highlander. I assume that this means that there were no sales the previous year:

```{r toyota grant highlander}
car_sales_data |>
  filter(modelName == "Toyota Grand Highlander")
```

It looks light I was right, there were no sales in 2022!

## 3. R. Rivera's "Car Crash information over time (1994-Present)"

For this analysis, I will be attempting to investigate car crashes by vehicle type and people type fatalities.

To outline a few definitions, vehicle type is a class of vehicle. These can be:

- Passenger Cars
- Light Trucks
- Large Trucks
- Motor Cycles
- Busses
- Other Vehicles (Limousines, Motorhomes, Farm Equipment, etc.)

Also, for people types, we will use the people types that are outlined in this data:

- Vehicle Occupants (Driver, Passenger)
- Motorcyclists
- Nonmotorists - Pedestrian
- Nonmotorists - Pedalcyclist

For a full list of descriptive definitions, please refer to the [NHTSA terms help website](https://www-fars.nhtsa.dot.gov/Help/Terms.aspx).

Although there was an [API offered](https://crashviewer.nhtsa.dot.gov/CrashAPI), it appears that there isn't a sufficient amount of information available to utilize it for these purposes. To ensure that I had the sufficient amount of granularity for the analysis, I needed to use the [Fatality and Injury Reporting System Tool Query](https://cdan.dot.gov/query) offered. Exports of this file can be found in this repository:

The datasets we will read below are:

1. Vehicles Involved in Fatal Crashes (`vehicle_data`) - This dataset contains the number of vehicles in fatal crashes by year, month, and vehicle type.
2. Persons Involved in Fatal Crashes (`people_data`) - This dataset contains the number of people involved in fatal crashes by year, month, and person type.
3. Fatal Motor Vehicle Crashes (`crash_data`) - This dataset contains the count of motor crash incidents by month, year, and the type of crash.

First we will need to download the data:
```{r read in the excel data}
# set up the URLs for the file's we need
urls <- list(
  c(
    "https://github.com/riverar9/cuny-msds/raw/main/data607/projects/project-2/vehicle_crash_data.xlsx",    # nolint: line_length_linter.
    "vehicle_crash_data.xlsx"
  ),
  c(
    "https://github.com/riverar9/cuny-msds/raw/main/data607/projects/project-2/fatal_crash_data.xlsx",      # nolint: line_length_linter.
    "fatal_crash_data.xlsx"
  ),
  c(
    "https://github.com/riverar9/cuny-msds/raw/main/data607/projects/project-2/people_fatality_data.xlsx",  # nolint: line_length_linter.
    "people_fatality_data.xlsx"
  )
)

# Iterate through the URLs and download them to the working directory
for (url in urls) {
  download.file(url[1], url[2], mode = "wb")
}
```

With all the files downloaded, we can read each one and format the data. We will do that with the below cells.

While working, I noticed that I should create a function that will convert the month names into an ordered factor.

```{r setting up factor function}
apply_month_factors <- function(df, month_column_name) {
  # Convert month_column_name into an ordered factor using months
  df <- df |>
     mutate(
      {{ month_column_name }} := factor({{ month_column_name }},
      levels = month.name,
      ordered = TRUE)
    )

  return(df)
}
```

```{r reading in the vehicle data}
vehicle_data <- read_excel(
  "vehicle_crash_data.xlsx",
  sheet = "CrashReport - Table 1",
  skip = 6
)

# specifying the column names
colnames(vehicle_data) <- c(
  "year",
  "month",
  "passenger_car",
  "light_truck_pickup",
  "light_truck_utility",
  "light_truck_van",
  "light_truck_other",
  "large_truck",
  "motorcycle",
  "bus",
  "other_vehicle",
  "vehicle_total"
)

# performing a forward fill on the year column
# and remove total from the month or year column.
# Finally, convert year into an integer
vehicle_data <- vehicle_data |>
  fill(year, .direction = "down") |>
  filter(month != "Total") |>
  filter(year != "Total") |>
  mutate(year = as.integer(year)) |>
  mutate(light_truck = light_truck_pickup +
           light_truck_utility + light_truck_van +
           light_truck_other) |>
  select(
    year,
    month,
    passenger_car,
    light_truck,
    large_truck,
    motorcycle,
    bus,
    other_vehicle,
    vehicle_total
  )

vehicle_data <- apply_month_factors(
  vehicle_data,
  month
)

str(vehicle_data)
```

```{r reading in the people data}
people_data <- read_excel(
  "people_fatality_data.xlsx",
  sheet = "CrashReport - Table 1",
  skip = 6
)

# specifying the column names
colnames(people_data) <- c(
  "year",
  "month",
  "car_driver",
  "car_passenger",
  "car_occupant",
  "other_1",
  "pedestrian",
  "bicyclist",
  "other_2",
  "other_3",
  "other_4",
  "other_5",
  "other_6",
  "other_7",
  "other_8",
  "other_9",
  "people_total"
)

# performing a forward fill on the year column
# and remove total from the month or year column.
# Then, convert year into an integer.
# Finally, combine all the others into one 
# and remove the rest
people_data <- people_data |>
  fill(year, .direction = "down") |>
  filter(month != "Total") |>
  filter(year != "Total") |>
  mutate(year = as.integer(year)) |>
  mutate(other_person = other_1 + other_2 +
           other_3 + other_4 + other_5 +
           other_6 + other_7 + other_8 +
           other_9) |>
  select(
    year,
    month,
    car_driver,
    car_passenger,
    car_occupant,
    pedestrian,
    bicyclist,
    other_person,
    people_total
  )

people_data <- apply_month_factors(
  people_data,
  month
)

str(people_data)
```

```{r reading in the crash data}
crash_data <- read_excel(
  "fatal_crash_data.xlsx",
  sheet = "CrashReport - Table 1",
  skip = 6
)

# specifying the column names
colnames(crash_data) <- c(
  "year",
  "month",
  "with_pedestrian",
  "without_pedestrian",
  "crash_total"
)

# performing a forward fill on the year column
# and remove total from the month or year column.
# Finally, convert year into an integer
crash_data <- crash_data |>
  fill(year, .direction = "down") |>
  filter(month != "Total") |>
  filter(year != "Total") |>
  mutate(year = as.integer(year))

crash_data <- apply_month_factors(
  crash_data,
  month
)

str(crash_data)
```

For ease of use, let's combine all of this data into one wide table. Because all of these datasets cover every month from 2007 to 2021, we can use a left join and expect a one-to-one relationship between each dataset.

As we are combining 3 datasets, we will nest a join within another join and this should return a dataset with Year and Month are the unique row identifier and we have columns from each dataset:

```{r combine all data}
combined_data <- left_join(
  crash_data,
  left_join(
    vehicle_data,
    people_data,
    by = c(
      "year",
      "month"
    )
  ),
  by = c(
    "year",
    "month"
  )
)

str(combined_data)
```

Now that we have all of our data, we can plot to see how car crashes have changed over time:

```{r crash graphs}
ggplot() +
  stat_summary(
    data = combined_data,
    aes(
      x = year,
      y = crash_total,
      color = "Total Crashes"
    ),
    fun = sum,
    geom = "line",
    size = 1.5,
  ) +
  stat_summary(
    data = combined_data,
    aes(
      x = year,
      y = people_total,
      color = "Total Fatalities"
    ),
    fun = sum,
    geom = "line",
    size = 1.5,
  ) +
  stat_summary(
    data = combined_data,
    aes(
      x = year,
      y = 10000 * (people_total / crash_total),
      color = "Fatalities per 10K Crashes"
    ),
    fun = mean,
    geom = "line",
    size = 1.5
  ) +
  labs(
    x = "Year",
    y = "Total Events",
    title = "Annual Total Car Crashes and Fatalities (2007 - 2021)",
    color = "Legend"
  ) +
  scale_color_brewer(
    palette = "Set1"
  ) +
  theme_minimal() +
  scale_x_continuous(
    breaks = seq(
      2007,
      2022,
      by = 1
    )
  ) +
  scale_y_continuous(
    breaks = seq(
      0,
      100000,
      by = 10000
    ),
    labels = scales::comma_format(
      scale = 1e-3,
      suffix = "K"
    )
  )

total_crashes_2007 <-  combined_data |>
  filter(year == 2007) |>
  summarise(total_crashes = sum(crash_total)) |>
  select(total_crashes)
total_crashes_2021 <- combined_data |>
  filter(year == 2021) |>
  summarise(total_crashes = sum(crash_total)) |>
  select(total_crashes)

print(
  paste(
    "There has been a",
    round(
      100 * (total_crashes_2021$total_crashes / total_crashes_2007$total_crashes - 1), 1
    ),
    "% increase in crashes."
  )
)
```

This graph tells us a bit. Firstly what stands out to me is that there was a significant decrease in the number of fatal crashes from 2007 to 2014, but there was a quick reversal since 2014 with the latest data suggesting that we are now experiencing more vehicle crashes than ever before. Additionally, we can visually notice a correlation between the total number of crashes and fatalities with the number of fatalities being much greater than the number of crashes. It is important to remember that this dataset is only the number of fatal crashes, so by definition we must expect that the number of fatalities must be at least equal to the number of crashes. The last piece plotted here is the number of fatalities per 10,000 crashes. We can see here that this number is pretty stable suggesting that there is a strong correlation between total fatalities and fatal crashes (honestly, duh) although we can also notice that it sits around 25,000. Meaning that, on average, each fatal crash results in at least 2 fatalities.

Although this graph did a lot to confirm what may have been initial assumptions, one big takeaway is that the average fatality per crash hasn't changed very much.

Here's an outstanding question, has there been any change in the groups of people who are experiencing fatalities? That is to say, is there a class of person who is experiencing a much higher or lower fatality rate?

In this next graph, we will plot the fatality rates by the person type. Fatality rate will be determined by a simple `(Person Class) / (Total Fatal Crashes)`

```{r fatality rate by person type}
ggplot() +
  stat_summary(
    data = combined_data,
    aes(
      x = year,
      y = car_driver / crash_total,
      color = "Car Driver"
    ),
    fun = mean,
    geom = "line",
    size = 1.5
  ) +
  stat_summary(
    data = combined_data,
    aes(
      x = year,
      y = car_passenger / crash_total,
      color = "Car Passenger"
    ),
    fun = mean,
    geom = "line",
    size = 1.5
  ) +
  stat_summary(
    data = combined_data,
    aes(
      x = year,
      y = pedestrian / crash_total,
      color = "Pedestrian"
    ),
    fun = mean,
    geom = "line",
    size = 1.5
  ) +
  stat_summary(
    data = combined_data,
    aes(
      x = year,
      y = bicyclist / crash_total,
      color = "Bicyclist"
    ),
    fun = mean,
    geom = "line",
    size = 1.5
  ) +
  stat_summary(
    data = combined_data,
    aes(
      x = year,
      y = other_person / crash_total,
      color = "Other Person"
    ),
    fun = mean,
    geom = "line",
    size = 1.5
  ) +
  stat_summary(
    data = combined_data,
    aes(
      x = year,
      y = people_total / crash_total,
      color = "Average fatalities per crash"
    ),
    fun = mean,
    geom = "line",
    size = 1.5
  ) +
  labs(
    x = "Year",
    y = "Fatalities per Crash",
    title = "Annual Total Car Crashes and Fatalities (2007 - 2021)",
    color = "People Class"
  ) +
  scale_color_brewer(
    palette = "Set1"
  ) +
  theme_minimal() +
  scale_x_continuous(
    breaks = seq(
      2007,
      2022,
      by = 1
    )
  ) +
  scale_y_continuous(
    breaks = seq(
      0,
      100000,
      by = 10000
    ),
    labels = scales::comma_format(
      scale = 1e-3,
      suffix = "K"
    )
  )
```

We've also plotted the total average number of fatalities per car crash to have a better visual feel for the relative contribution to the whole. From here, we can see that car drivers and pedestrians have seen an increase while car passengers have decreased. Although this doesn't help answer the question of why as there could be much fewer car passengers due to ride shares, loneliness, or other reasons.

I would like to zoom in on the pedestrian count, as they're fairly unprotected from vehicle crashes:

```{r looking at pedestrian crashes}
ggplot() +
  stat_summary(
    data = combined_data,
    aes(
      x = year,
      y = with_pedestrian,
      color = "Crashes with Pedestrians"
    ),
    fun = sum,
    geom = "line",
    size = 1.5
  ) +
  stat_summary(
    data = combined_data,
    aes(
      x = year,
      y = pedestrian,
      color = "Pedestrian Fatalities"
    ),
    fun = sum,
    geom = "line",
    size = 1.5
  ) +
  stat_summary(
    data = combined_data,
    aes(
      x = year,
      y = bicyclist,
      color = "Bicyclist Fatalities"
    ),
    fun = sum,
    geom = "line",
    size = 1.5
  ) +
  labs(
    x = "Year",
    y = "Sum of Events",
    title = "Pedestrian Fatalities over time (2007 - 2021)",
    color = "Event Type"
  ) +
  scale_color_brewer(
    palette = "Set1"
  ) +
  theme_minimal() +
  scale_x_continuous(
    breaks = seq(
      2007,
      2022,
      by = 1
    )
  ) +
  scale_y_continuous(
    breaks = seq(
      0,
      10000,
      by = 500
    ),
    labels = scales::comma_format(
      scale = 1e-3,
      suffix = "K"
    )
  )

pedestrian_fatalities_2007 <-  combined_data |>
  filter(year == 2007) |>
  summarise(total_fatalities = sum(pedestrian))

pedestrian_fatalities_2021 <- combined_data |>
  filter(year == 2021) |>
  summarise(total_fatalities = sum(pedestrian))

print(
  paste(
    "There has been a",
    round(
      100 * (pedestrian_fatalities_2021$total_fatalities / pedestrian_fatalities_2007$total_fatalities - 1), 1
    ),
    "% increase in crashes."
  )
)
```

This is not good. We are seeing a pretty significant increase in pedestrian fatalities from 2007 to 2021, a 54.6% increase!

According to the [US Department of Energy's AFDC](https://afdc.energy.gov/data/10315), there has not been a significant change in the total number of vehicle miles in the US since 2007 (3.01 trillion miles) to 2021 (2.83 trillion miles).

Combining the crash data with the number of total miles driven it's pretty apparent that something is going on that is causing for more dangerous driving across the country. Additionally, pedestrians and car drivers are the major classes of people who are victims of these crashes.

Now finally, I would like to see if there is anything we can find by looking at the vehicle types:

```{r vehicle type crash info}
ggplot() +
  stat_summary(
    data = combined_data,
    aes(
      x = year,
      y = passenger_car,
      color = "Passenger Car"
    ),
    fun = sum,
    geom = "line",
    size = 1.5
  ) +
  stat_summary(
    data = combined_data,
    aes(
      x = year,
      y = light_truck,
      color = "Light Truck"
    ),
    fun = sum,
    geom = "line",
    size = 1.5
  ) +
  stat_summary(
    data = combined_data,
    aes(
      x = year,
      y = large_truck,
      color = "Large Truck"
    ),
    fun = sum,
    geom = "line",
    size = 1.5
  ) +
  stat_summary(
    data = combined_data,
    aes(
      x = year,
      y = motorcycle,
      color = "Motorcycle"
    ),
    fun = sum,
    geom = "line",
    size = 1.5
  ) +
  stat_summary(
    data = combined_data,
    aes(
      x = year,
      y = bus,
      color = "Bus"
    ),
    fun = sum,
    geom = "line",
    size = 1.5
  ) +
  stat_summary(
    data = combined_data,
    aes(
      x = year,
      y = other_vehicle,
      color = "Other Vehicle"
    ),
    fun = sum,
    geom = "line",
    size = 1.5
  ) +
  labs(
    x = "Year",
    y = "Vehicles Involved in Crashes",
    title = "Vehicles Involved in Crashes over time by Type",
    color = "Vehicle Type"
  ) +
  scale_color_brewer(
    palette = "Set1"
  ) +
  theme_minimal() +
  scale_x_continuous(
    breaks = seq(
      2007,
      2022,
      by = 1
    )
  ) +
  scale_y_continuous(
    breaks = seq(
      0,
      30000,
      by = 2500
    ),
    labels = scales::comma_format(
      scale = 1e-3,
      suffix = "K"
    )
  )
```

Wow, again we see some major changes and a pretty worrying trend. My intuition tells me that the majority vehicle is a passenger car or a light truck and it seems that these two classes of vehicles are involved with the most crashes. Although, another interesting item to point out is that the number of light trucks has absolutely skyrocketed since 2019, not experiencing the same dip that is seen with passenger cars.

Here we may be able to find some overlap between that great increase in light truck crashes and the sales dataset. Revisiting the graph of the cars with the highest increase in sales:

```{r bringing back the sales graph}
car_sales_yoy
```

One thing I noticed here, is that all but 2 vehicles with the highest number of sales increase year over year would be classified as a light truck in the NHTSA data. Which means that light trucks may have a larger share of the vehicle type on the road which could help explain the increase in crashes with vehicles in this category.

These trends do not prove anything, but they are evidence that the roads are becoming more dangerous per mile driven for most people who interact with it.

# Conclusion

In this exercise we've explored data across the Consumer Price Index, Vehicle Sales, and Fatal Crashes. Although there were quite a few things we've uncovered I will be breaking it down into two categories below:

## In the respective dataset

This section contains the insights found in each individual dataset

1. The cost of energy (gas and electricity) has decreased year over year
2. The cost of used vehicles has decreased year over year
3. The cost of motor vehicle insurance has increased 20.6%
4. There have been a multitude of car models with incredible Year over Year sales growth
5. The majority of cars with the largest Year over Year sales growth are SUVs (Light Trucks)
6. The total number of total car crashes has increased by 5.5% from 2007 to present
7. The number of pedestrian fatalities has increased 54.6%
8. The number of trucks involved in crashes has increased


Combining some of these insights we can see:

1. The number of pedestrian fatalities has quickly outgrown the total number of car crashes, suggesting that something has happened causing for this increase.
2. The increase in sales of light trucks year over year may be a continuing trend, which could explain some of the increase light trucks have in fatal crashes.
